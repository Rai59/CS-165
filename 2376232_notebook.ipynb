{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3501ec7a5a5e",
   "metadata": {},
   "source": [
    "# Forest Fire Prediction — Algeria\n",
    "**Student ID:** 2376232  \n",
    "**Module:** CS-165 — Data Science Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb52590ce0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this study, we analyse meteorological and environmental data to predict forest fires in Algeria. Using a dataset of 243 instances, we employ machine learning models — Logistic Regression, k-Nearest Neighbours (k-NN), and Random Forest — to classify observations into \"fire\" and \"not fire\" categories. The dataset includes key climate variables such as temperature, humidity, wind speed, and fire weather indices, which serve as predictors for fire occurrence. Through data preprocessing, feature engineering, and model evaluation, this study develops an effective early-warning system for wildfire detection.\n",
    "\n",
    "## Main Objective\n",
    "\n",
    "The primary objective is to predict the likelihood of forest fires based on weather conditions and environmental factors. By leveraging machine learning, we aim to enhance fire prevention efforts, allowing authorities to take preemptive action before wildfires spread uncontrollably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff1a27b0f8",
   "metadata": {},
   "source": [
    "## Proposed Solution\n",
    "\n",
    "### Methodology\n",
    "\n",
    "This study follows the PPDAC (Problem, Plan, Data, Analysis, Conclusion) framework to develop a forest fire prediction system:\n",
    "\n",
    "**Problem:** Can we predict forest fire occurrence using meteorological and fire weather index data?\n",
    "\n",
    "**Plan:** We approach this as a binary classification task, comparing three algorithms with different learning paradigms:\n",
    "\n",
    "1. **Logistic Regression** — A linear baseline model that estimates fire probability using a weighted combination of features. Chosen for interpretability and to establish whether the relationship between weather variables and fire occurrence is approximately linear.\n",
    "\n",
    "2. **k-Nearest Neighbours (k-NN)** — A non-parametric, instance-based learner that classifies based on similarity to nearby observations. Chosen to capture potential non-linear patterns without assuming a specific functional form. Requires feature scaling because it computes Euclidean distances.\n",
    "\n",
    "3. **Random Forest** — An ensemble method combining multiple decision trees with bootstrap aggregation. Chosen for its ability to model complex feature interactions and provide feature importance rankings.\n",
    "\n",
    "**Evaluation Strategy:** Models are trained on 80% of the data and evaluated on a held-out 20% test set using stratified sampling to preserve class distribution. 5-fold cross-validation is applied to all models to ensure results are not an artefact of a single split. Performance is measured using accuracy, precision, recall, and F1-score to account for potential class imbalance.\n",
    "\n",
    "This multi-model comparison allows us to assess whether fire prediction requires complex non-linear modelling or whether simpler approaches suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2c58ca25d",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "To ensure high-quality predictions, our dataset undergoes several preprocessing steps:\n",
    "\n",
    "- **Data Cleaning:** Handling missing values and stripping whitespace from column names.\n",
    "- **Feature Scaling:** Applying StandardScaler (fit on training data only) so distance-based models (k-NN) are not dominated by features with large numeric ranges.\n",
    "- **Label Encoding:** Converting the \"fire\" / \"not fire\" target strings to binary integers (1 / 0).\n",
    "- **Stratified Splitting:** Preserving the fire/not-fire class ratio in both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52922b043d8b",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce7726b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef3fb2305a",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We load the Algerian Forest Fires dataset and inspect its structure, data types, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29407e997b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = [\n",
    "    'Day', 'Month', 'Temp', 'RH', 'Ws', 'Rain',\n",
    "    'FFMC', 'DMC', 'DC', 'ISI', 'BUI', 'FWI', 'Target'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('ForestFire.csv', header=None, names=column_name)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print('First five rows:')\n",
    "print(df.head())\n",
    "\n",
    "print('\\nDataset info:')\n",
    "print(df.info())\n",
    "\n",
    "print('\\nStatistical summary:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ba403993a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "We examine:\n",
    "- Feature distributions (histograms)\n",
    "- Class distribution of the Target variable\n",
    "- Correlation between features\n",
    "- Regional and seasonal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c559ab6eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "df.hist(figsize=(12, 10), bins=20)\n",
    "plt.suptitle('Feature Distributions', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de61b17ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardise Target labels\n",
    "df['Target'] = df['Target'].str.lower().str.strip().replace({\n",
    "    'notfire': 'not fire',\n",
    "    'fire': 'fire'\n",
    "})\n",
    "\n",
    "print('Fire status counts:')\n",
    "print(df['Target'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(data=df, x='Target', hue='Target',\n",
    "              palette={'fire': 'red', 'not fire': 'green'}, legend=False)\n",
    "plt.title('Forest Fire Cases')\n",
    "plt.xlabel('Fire Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447566ee4521",
   "metadata": {},
   "source": [
    "## Correlation Heatmap\n",
    "\n",
    "High correlation between features could indicate multicollinearity. The FWI system features (FFMC, DMC, DC, ISI, BUI) are mathematically derived from each other, so strong correlations are expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30abe75b7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be7dfa0be1",
   "metadata": {},
   "source": [
    "## Regional Analysis\n",
    "\n",
    "The Algerian Forest Fires dataset combines observations from two distinct regions:\n",
    "- **Bejaia Region** (rows 1-122): located in the northeast\n",
    "- **Sidi-Bel Abbes Region** (rows 123-243): located in the northwest\n",
    "\n",
    "Analysing these regions separately reveals whether fire patterns differ geographically, which a single aggregated analysis would miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c74e84bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign region labels\n",
    "df['Region'] = ['Bejaia' if i < 122 else 'Sidi-Bel Abbes' for i in range(len(df))]\n",
    "\n",
    "print('Fire counts by region:')\n",
    "print(df.groupby(['Region', 'Target']).size().unstack(fill_value=0))\n",
    "\n",
    "# ── Plot 1: Fire by Region and Month ──────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "region_fire = df.groupby(['Region', 'Target']).size().unstack(fill_value=0)\n",
    "region_fire[['not fire', 'fire']].plot(kind='bar', ax=axes[0],\n",
    "                                        color=['green', 'red'], edgecolor='black')\n",
    "axes[0].set_title('Fire Occurrence by Region', fontsize=14)\n",
    "axes[0].set_xlabel('Region')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend(['Not Fire', 'Fire'])\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "monthly_fire = df.groupby(['Month', 'Target']).size().unstack(fill_value=0)\n",
    "monthly_fire[['not fire', 'fire']].plot(kind='bar', ax=axes[1],\n",
    "                                         color=['green', 'red'], edgecolor='black')\n",
    "axes[1].set_title('Fire Occurrence by Month', fontsize=14)\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticklabels(['June', 'July', 'August', 'September'], rotation=0)\n",
    "axes[1].legend(['Not Fire', 'Fire'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ── Plot 2: Key feature distributions by fire status ─────────────────────\n",
    "key_features = ['Temp', 'RH', 'Ws', 'FWI', 'DC', 'ISI']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    sns.boxplot(data=df, x='Target', y=feature, ax=axes[idx],\n",
    "                palette={'fire': 'red', 'not fire': 'green'})\n",
    "    axes[idx].set_title(f'{feature} Distribution by Fire Status', fontsize=12)\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "plt.suptitle('Feature Distributions: Fire vs Not Fire', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "EXPLORATORY ANALYSIS INSIGHTS:\n",
    "==============================\n",
    "1. REGIONAL DIFFERENCES:\n",
    "   - Sidi-Bel Abbes shows higher fire occurrence than Bejaia\n",
    "   - Suggests geographical/climatic differences affect fire risk\n",
    "\n",
    "2. SEASONAL PATTERN:\n",
    "   - August has the highest fire occurrence\n",
    "   - June shows lowest fire risk (early summer, vegetation not yet fully dry)\n",
    "\n",
    "3. DISTINGUISHING FEATURES:\n",
    "   - FWI: Clear separation between fire/not-fire cases\n",
    "   - DC: Fire cases show significantly higher drought code values\n",
    "   - Temperature: Fire cases cluster at higher temperatures (>32 C)\n",
    "   - RH: Fire cases occur at lower humidity levels\n",
    "\n",
    "4. CLASS BALANCE:\n",
    "   - Dataset is roughly balanced (138 fire vs 105 not-fire)\n",
    "   - Stratified splitting is important to preserve this ratio\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d442f3532",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Encode Categorical Target\n",
    "\n",
    "The Target variable (\"fire\" / \"not fire\") is converted to binary integers for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbade7b341f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode: fire = 1, not fire = 0\n",
    "le = LabelEncoder()\n",
    "df['Target'] = le.fit_transform(df['Target'])\n",
    "\n",
    "print('Encoded class mapping:', dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "print('Class distribution after encoding:')\n",
    "print(df['Target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457694ac0a9",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "\n",
    "We apply three classification algorithms and evaluate each using 5-fold stratified cross-validation alongside the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbd4a4196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. PREPARE DATA ──────────────────────────────────────────────────────\n",
    "# Drop Target and Region (added during EDA, not a predictive feature)\n",
    "X = df.drop(columns=['Target', 'Region'])\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale — fit on train only, transform both\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set size: {len(X_train)} samples')\n",
    "print(f'Test set size:     {len(X_test)} samples')\n",
    "print(f'Class distribution in training set:\\n{y_train.value_counts()}')\n",
    "\n",
    "# ── 2. TRAIN MODELS ─────────────────────────────────────────────────────\n",
    "results = {}\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "log_model    = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_cv       = cross_val_score(log_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "y_pred_log   = log_model.predict(X_test_scaled)\n",
    "results['Logistic Regression'] = {\n",
    "    'cv_mean': log_cv.mean(), 'cv_std': log_cv.std(),\n",
    "    'test_acc': accuracy_score(y_test, y_pred_log), 'preds': y_pred_log\n",
    "}\n",
    "print(f\"\\n{'='*50}\\nLOGISTIC REGRESSION\\n{'='*50}\")\n",
    "print(f'5-Fold CV: {log_cv.mean():.4f} (+/- {log_cv.std()*2:.4f})')\n",
    "print(f'Test Acc:  {accuracy_score(y_test, y_pred_log):.4f}')\n",
    "\n",
    "# --- k-NN (scaled — required for distance-based model) ---\n",
    "knn_model    = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cv       = cross_val_score(knn_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_knn   = knn_model.predict(X_test_scaled)\n",
    "results['k-NN'] = {\n",
    "    'cv_mean': knn_cv.mean(), 'cv_std': knn_cv.std(),\n",
    "    'test_acc': accuracy_score(y_test, y_pred_knn), 'preds': y_pred_knn\n",
    "}\n",
    "print(f\"\\n{'='*50}\\nk-NEAREST NEIGHBOURS (k=5)\\n{'='*50}\")\n",
    "print(f'5-Fold CV: {knn_cv.mean():.4f} (+/- {knn_cv.std()*2:.4f})')\n",
    "print(f'Test Acc:  {accuracy_score(y_test, y_pred_knn):.4f}')\n",
    "\n",
    "# --- Random Forest (tree-based, no scaling needed) ---\n",
    "rf_model     = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cv        = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf    = rf_model.predict(X_test)\n",
    "results['Random Forest'] = {\n",
    "    'cv_mean': rf_cv.mean(), 'cv_std': rf_cv.std(),\n",
    "    'test_acc': accuracy_score(y_test, y_pred_rf), 'preds': y_pred_rf\n",
    "}\n",
    "print(f\"\\n{'='*50}\\nRANDOM FOREST\\n{'='*50}\")\n",
    "print(f'5-Fold CV: {rf_cv.mean():.4f} (+/- {rf_cv.std()*2:.4f})')\n",
    "print(f'Test Acc:  {accuracy_score(y_test, y_pred_rf):.4f}')\n",
    "\n",
    "# ── 3. COMPARISON SUMMARY ───────────────────────────────────────────────\n",
    "print(f\"\\n{'='*60}\\nMODEL COMPARISON SUMMARY\\n{'='*60}\")\n",
    "print(f\"{'Model':<25} {'CV Accuracy':<28} {'Test Accuracy'}\")\n",
    "print('-'*60)\n",
    "for name, m in results.items():\n",
    "    cv_str = f\"{m['cv_mean']:.4f} (+/- {m['cv_std']*2:.4f})\"\n",
    "    print(f\"{name:<25} {cv_str:<28} {m['test_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1eba7ab8fb",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We evaluate the best-performing model (Random Forest) using a confusion matrix, precision, recall, and F1-score. For fire prediction systems, **minimising false negatives is critical** — a missed fire prediction is far more dangerous than a false alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e2b788019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix — Random Forest\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Not Fire', 'Fire'],\n",
    "            yticklabels=['Not Fire', 'Fire'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix — Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eeb40a299d",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8045798ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Classification Report:')\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Not Fire', 'Fire']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b727fab81",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Random Forest provides a feature importance score indicating how much each variable contributes to reducing impurity across all trees. This reveals which weather variables are most predictive of fire occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef3100734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.Series(rf_model.feature_importances_,\n",
    "                       index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = importance.plot(kind='barh', color='#1f77b4')\n",
    "\n",
    "for i, v in enumerate(importance):\n",
    "    ax.text(v + 0.005, i, f'{v:.3f}', color='black', va='center')\n",
    "\n",
    "plt.title('Feature Importance for Forest Fire Prediction', fontsize=16, pad=20)\n",
    "plt.xlabel('Relative Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "for spine in ['top', 'right']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef31f18fec",
   "metadata": {},
   "source": [
    "## Results Discussion\n",
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "| Model | CV Accuracy | Test Accuracy | Key Characteristic |\n",
    "|-------|-------------|---------------|-------------------|\n",
    "| Logistic Regression | ~94% | 93.9% | Linear decision boundary |\n",
    "| k-Nearest Neighbours | ~94% | 93.9% | Instance-based, local patterns |\n",
    "| Random Forest | ~96% | 95.9% | Non-linear, feature interactions |\n",
    "\n",
    "### Why Did Random Forest Outperform?\n",
    "\n",
    "The 2% accuracy improvement of Random Forest over the linear models suggests that **fire occurrence involves non-linear feature interactions** that simpler models cannot capture. Specifically:\n",
    "\n",
    "1. **Feature Interactions Matter:** Fire risk is not simply \"high temperature = fire\". Rather, it is combinations like high temperature + low humidity + high wind speed + accumulated drought (DC). Random Forest naturally captures these interactions through its tree-based splitting.\n",
    "\n",
    "2. **The FWI System is Hierarchical:** The Fire Weather Index features (FFMC, DMC, DC, ISI, BUI, FWI) are calculated from each other in a cascade. Random Forest can exploit this hierarchical structure, while Logistic Regression treats each feature independently.\n",
    "\n",
    "3. **Similar LR and k-NN Performance:** Both achieved 93.9%, suggesting the problem has a reasonably clear decision boundary — most cases are unambiguously fire or not-fire based on weather conditions. The remaining ~6% of cases likely sit in ambiguous boundary regions where weather is moderate.\n",
    "\n",
    "### Feature Importance Analysis\n",
    "\n",
    "From the Random Forest feature importance plot:\n",
    "\n",
    "| Rank | Feature | Importance | Interpretation |\n",
    "|------|---------|------------|----------------|\n",
    "| 1 | FWI | ~0.25 | The aggregate Fire Weather Index is the strongest single predictor — validates the Canadian FWI system's design |\n",
    "| 2 | DC (Drought Code) | ~0.15 | Long-term moisture deficit in deep organic layers is critical |\n",
    "| 3 | Temperature | ~0.12 | Direct heat effect on ignition probability |\n",
    "| 4 | ISI (Initial Spread Index) | ~0.10 | Wind-driven fire spread potential |\n",
    "\n",
    "**Practical Implication:** For fire prevention authorities, monitoring FWI and DC values provides the highest predictive value. When FWI exceeds a threshold (observable from the boxplots), fire risk increases dramatically.\n",
    "\n",
    "### Confusion Matrix Interpretation\n",
    "\n",
    "The Random Forest confusion matrix shows:\n",
    "- **True Negatives (Not Fire correctly predicted):** ~24/25 cases\n",
    "- **True Positives (Fire correctly predicted):** ~23/24 cases\n",
    "- **False Positives:** ~1 case (predicted fire when none occurred) — low cost, triggers unnecessary caution\n",
    "- **False Negatives:** ~1 case (missed fire) — **HIGH cost**, dangerous for prevention\n",
    "\n",
    "For fire prediction systems, **minimising false negatives is critical** — missing a fire prediction could have catastrophic consequences. The current 95% recall for the fire class is good but not perfect.\n",
    "\n",
    "### Regional Findings\n",
    "\n",
    "The EDA revealed that Sidi-Bel Abbes region has higher fire occurrence than Bejaia. This could be due to:\n",
    "- Different vegetation types (fuel load)\n",
    "- Microclimatic differences\n",
    "- Altitude and terrain effects\n",
    "\n",
    "**Limitation:** The model does not include region as a feature. Adding it could improve predictions but would reduce generalisability to new regions.\n",
    "\n",
    "### Cross-Validation Insights\n",
    "\n",
    "The small gap between CV accuracy and test accuracy (< 1%) suggests:\n",
    "- Models are not severely overfitting\n",
    "- The 80/20 split is representative of the overall distribution\n",
    "- Results should generalise to new data from the same distribution\n",
    "\n",
    "However, the CV standard deviation (~2-3%) indicates some sensitivity to which samples appear in each fold — expected given the small dataset size (243 samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37af9df169f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This study compared three classification algorithms — Logistic Regression, k-Nearest Neighbours, and Random Forest — for predicting forest fire occurrence in Algeria using meteorological and fire weather index data.\n",
    "\n",
    "**Random Forest was the strongest performer**, achieving 95.92% test accuracy with balanced precision and recall across both classes. Its advantage stems from ensemble averaging: by combining 100 independently trained decision trees, it reduces the variance that makes a single tree prone to overfitting on a small dataset. It also captures non-linear interactions between weather variables without requiring explicit feature engineering.\n",
    "\n",
    "**Feature importance analysis highlights that drought-related indices (FWI, DC, DMC) are the strongest predictors**, not instantaneous weather readings like wind speed alone. This indicates that sustained fuel moisture depletion over days and weeks is more predictive of fire occurrence than any single day's conditions — a finding with direct practical relevance for fire-risk monitoring.\n",
    "\n",
    "**Limitations:** The dataset contains only 243 observations from a single season (June-September) in northern Algeria, limiting generalisation. A random train/test split does not respect temporal ordering; a time-based evaluation would be more realistic. Class imbalance, if present in unseen data, means accuracy alone may overstate performance.\n",
    "\n",
    "**Future work** could explore SMOTE-based oversampling to address class imbalance, hyperparameter tuning (optimising k for k-NN, tree depth for Random Forest), adding region as a categorical feature, and temporal cross-validation for a more honest estimate of real-world predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adb08f3c5f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Abid, F. (2021). A Survey of Machine Learning Algorithms Based Forest Fires Prediction and Detection Systems. *Fire Technology*, 57(2), 559-590. https://doi.org/10.1007/s10694-020-01056-z\n",
    "\n",
    "Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32. https://doi.org/10.1023/A:1010933404324\n",
    "\n",
    "Cover, T. M., & Hart, P. E. (1967). Nearest Neighbor Pattern Classification. *IEEE Transactions on Information Theory*, 13(1), 21-27. https://doi.org/10.1109/TIT.1967.1053964\n",
    "\n",
    "Canadian Forest Service. (2023). *The Canadian Forest Fire Weather Index (FWI) System*. Natural Resources Canada. https://cwfis.cfs.nrcan.gc.ca/background/summary/fwi\n",
    "\n",
    "UCI Machine Learning Repository. (2019). *Algerian Forest Fires Dataset*. University of California, Irvine. https://archive.ics.uci.edu/ml/datasets/Algerian+Forest+Fires+Dataset++"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
